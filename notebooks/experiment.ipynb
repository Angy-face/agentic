{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c773a0",
   "metadata": {},
   "source": [
    "# Create label for Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea38fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_based_classify(text):\n",
    "    # คำสำคัญที่แสดงถึงการคาดการณ์ (prediction)\n",
    "    prediction_keywords = [\n",
    "        \"อ่านคำถาม\",\"ตอบคำถาม\",\"Read the\",\"Answer the\"\n",
    "    ]\n",
    "\n",
    "    # ตรวจสอบว่าในข้อความมีคำคาดการณ์หรือไม่\n",
    "    if any(keyword in text for keyword in prediction_keywords):\n",
    "        return \"multiple\"\n",
    "    return \"prediction\"\n",
    "\n",
    "#fucntion to split text by \\n and merge after first array with space\n",
    "#remove specific keyword after join\n",
    "remove = [\"คำถาม\",\"Question\",\":\",\"Q\",\"บริบท\",\"Context\",\"Answer\",\"คำตอบ\"]\n",
    "def split_text(text):\n",
    "    text = text.split(\"\\n\")\n",
    "    text = \" \".join(text[1:])\n",
    "    for i in remove:\n",
    "        text = text.replace(i,\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv('/home/siamai/data/Focus/agentic/data/test.csv')\n",
    "# Apply the classifier\n",
    "test[\"message_type\"] = test[\"query\"].apply(rule_based_classify)\n",
    "test[\"message_sliced\"] = test[\"query\"].apply(split_text)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60417ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "ROUTER_PATH = \"/home/siamai/data/chuniji/week8/FinetunedBERT/BERTfine/Onfire\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ROUTER_PATH)\n",
    "model_cls = AutoModelForSequenceClassification.from_pretrained(ROUTER_PATH, num_labels=2).cuda()\n",
    "model_cls.eval()\n",
    "def classify_question(query: str) -> str:    \n",
    "    mapping = {0: \"multiple_choice\", 1: \"timeseries\"}    \n",
    "    inputs = tokenizer_cls(query, padding=True, truncation=True, return_tensors=\"pt\").to(model_cls.device)\n",
    "    outputs = model_cls(**inputs)    \n",
    "    pred = torch.argmax(outputs.logits, dim=1).item()    \n",
    "    return mapping.get(pred, \"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c1bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare dataset\n",
    "df = test.copy()\n",
    "df[\"labels\"] = df[\"message_type\"].apply(lambda x: 1 if x == \"prediction\" else 0)  # MUST be 'labels'\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "# # Load tokenizer and model\n",
    "# model_name = \"xlm-roberta-base\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# # Tokenizer function that includes 'labels'\n",
    "def tokenize(example):\n",
    "    tokens = tokenizer(example[\"message_sliced\"], truncation=True, padding=\"max_length\")\n",
    "    tokens[\"labels\"] = example[\"labels\"]  # ✅ Add labels here\n",
    "    return tokens\n",
    "\n",
    "# Tokenize\n",
    "tokenized_dataset = dataset.map(tokenize)\n",
    "\n",
    "# Split\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.6)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=None,\n",
    "    per_device_train_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_steps=100,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Optional: Accuracy metric\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, preds),\n",
    "            \"f1_score\":f1_score(labels, preds)}\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model_cls,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4c084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_pretrained(\"../model/xlm_routing\")\n",
    "# tokenizer.save_pretrained(\"../model/xlm_routing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "predictions, _, _ = trainer.predict(eval_dataset)\n",
    "y_pred = predictions.argmax(axis=1)\n",
    "\n",
    "cm = confusion_matrix(eval_dataset[\"labels\"], y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc485f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0f233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"labels\":y_pred,\n",
    "                   \"true_labels\":eval_dataset[\"labels\"],\n",
    "                   \"query\":eval_dataset[\"query\"]\n",
    "                   })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd316b50",
   "metadata": {},
   "source": [
    "# Call local API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2821cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Answer the question with the appropriate options A, B, C and D. Please respond with the exact answer A, B, C or D only. Do not be verbose or provide extra information. \n",
      "Question: According to COSO, which of the following is the most effective method to transmit a message of ethical behavior throughout an organization?\n",
      "Answer Choices: A: Demonstrating appropriate behavior by example., B: Strengthening internal audit’s ability to deter and report improper behavior., C: Removing pressures to meet unrealistic targets, particularly for short-term results., D: Specifying the competence levels for every job in an organization and translating those levels to requisite knowledge and skills. \n",
      "Answer: A: Demonstrating appropriate behavior by example.\n",
      "Explanation: According to COSO, the most effective method to transmit a message of ethical behavior throughout an organization is by demonstrating appropriate behavior by example. This means that senior leaders and managers should set the tone for ethical behavior by practicing what they preach. By doing so, they can serve as role models for other employees and reinforce the message that ethical behavior is valued and expected in the organization.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_url = \"http://localhost:6666/generate\" \n",
    "input = \"\"\"Answer the question with the appropriate options A, B, C and D. Please respond with the exact answer A, B, C or D only. Do not be verbose or provide extra information. \n",
    "Question: According to COSO, which of the following is the most effective method to transmit a message of ethical behavior throughout an organization?\n",
    "Answer Choices: A: Demonstrating appropriate behavior by example., B: Strengthening internal audit’s ability to deter and report improper behavior., C: Removing pressures to meet unrealistic targets, particularly for short-term results., D: Specifying the competence levels for every job in an organization and translating those levels to requisite knowledge and skills. \n",
    "Answer:\"\"\"\n",
    "\n",
    "data = {\n",
    "    \"prompt\": input,\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json()[\"generated_text\"])\n",
    "else:\n",
    "    print(f\"Failed with status {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "574a1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(query):\n",
    "  prompt = f\"\"\"\n",
    "  You are a classifier that categorizes a question into one of two types: `multiple` or `prediction`.\n",
    "\n",
    "  Definitions:\n",
    "\n",
    "  1. `multiple`:  \n",
    "  - These questions ask the user to choose the correct answer from a set of options (e.g., A, B, C, D).  \n",
    "  - They often include phrases like \"เลือกตัวเลือกที่เหมาะสม\" or \"โปรดตอบด้วย A, B, C หรือ D เท่านั้น\".\n",
    "\n",
    "  Example:  \n",
    "  \"ตอบคำถามด้วยตัวเลือกที่เหมาะสม A, B, C และ D โปรดตอบด้วยคำตอบที่ถูกต้อง A, B, C หรือ D เท่านั้น อย่าใช้คำฟุ่มเฟือยหรือให้ข้อมูลเพิ่มเติม  \n",
    "  คำถาม: ______ สถานที่ทำงานเกี่ยวข้องกับการเสริมสร้างศักยภาพให้พนักงาน ตัวอย่างเช่น 'job enrichment'  \n",
    "  ตัวเลือกคำตอบ: A: Re-invigorating, B: Re-flourishing, C: Revitalizing, D: Rehumanizing\"\n",
    "\n",
    "  2. `prediction`:  \n",
    "  - These questions require interpretation of data, forecasting, or estimating outcomes based on patterns.  \n",
    "  - Often found in financial, statistical, or analytical contexts.\n",
    "\n",
    "  Example:  \n",
    "  \"วิเคราะห์ข้อมูลและทวีตเพื่อสรุปว่าราคาปิดของ $gs จะปรับตัวขึ้นหรือลงในวันที่ 2017-12-20 โปรดยืนยันว่าขึ้นหรือลง  \n",
    "  บริบท: วันที่, เปิด, สูง, ต่ำ, ปิด, ปิดปรับ, เพิ่ม 5%, ...  \n",
    "  2017-12-19, 2.0, 2.1, -0.1, -1.4, -1.4, ...\"\n",
    "\n",
    "  ---\n",
    "\n",
    "  **Your task:**  \n",
    "  Classify the following query as either `multiple` or `prediction`.  \n",
    "  **Only return one of the following two words (in lowercase) without explanation**:  \n",
    "  - `multiple`  \n",
    "  - `prediction`\n",
    "\n",
    "  Query:  \n",
    "  \\\"\\\"\\\"{query}\\\"\\\"\\\"\n",
    "  Assistance :\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  data = {\n",
    "  \"prompt\": prompt,\n",
    "  \"temperature\": 0.1}\n",
    "  response = requests.post(api_url, json=data)\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9b4db3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: Answer the question with the appropriate options A, B, C and D. Please respond with the exact answer A, B, C or D only. Do not be verbose or provide extra information. \n",
      "Question: Which of the following statements are true concerning maximum likelihood (ML) estimation in the context of GARCH models?\n",
      "\n",
      "i) Maximum likelihood estimation selects the parameter values that maximise the\n",
      "\n",
      "probability that we would have actually observed the values of the series y that we\n",
      "\n",
      "actually did.\n",
      "\n",
      "\n",
      "ii) GARCH models can only be estimated by ML and not by OLS\n",
      "\n",
      "\n",
      "iii) For estimation of a standard linear model (with no GARCH), the OLS and ML\n",
      "\n",
      "estimates for the slope and intercept parameters will be identical but the estimator\n",
      "\n",
      "for the variance of the disturbances is slightly different\n",
      "\n",
      "\n",
      "iv) Most computer packages use numerical procedures to estimate GARCH models\n",
      "\n",
      "rather than a set of analytical formulae\n",
      "Answer Choices: A: (ii) and (iv) only, B: (i) and (iii) only, C: (i), (ii), and (iii) only, D: (i), (ii), (iii), and (iv) \n",
      "Answer:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Assistant: The US Global Jets ETF (JETS) is a fund that invests in companies that are active in the global commercial aerospace industry. Its holdings include companies that manufacture and service commercial aircraft, aircraft parts and equipment, as well as companies that provide ground support services and other'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomly select row from dataframe as input\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/home/siamai/data/Focus/agentic/data/test.csv\")\n",
    "user_input = df.sample(n=1).iloc[0][\"query\"]\n",
    "print(f\"User input: {user_input}\")\n",
    "print(\"-\"*50)   \n",
    "response = classify(user_input)\n",
    "response.json()[\"generated_text\"].split(\"\\n\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbe3c9",
   "metadata": {},
   "source": [
    "# Vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a2123af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(query):\n",
    "  prompt = f\"\"\"\n",
    "  You are a classifier that categorizes a question into one of two types: `multiple` or `prediction`.\n",
    "\n",
    "  Definitions:\n",
    "\n",
    "  1. `multiple`:  \n",
    "  - These questions ask the user to choose the correct answer from a set of options (e.g., A, B, C, D).  \n",
    "  - They often include phrases like \"เลือกตัวเลือกที่เหมาะสม\" or \"โปรดตอบด้วย A, B, C หรือ D เท่านั้น\".\n",
    "\n",
    "  Example:  \n",
    "  \"ตอบคำถามด้วยตัวเลือกที่เหมาะสม A, B, C และ D โปรดตอบด้วยคำตอบที่ถูกต้อง A, B, C หรือ D เท่านั้น อย่าใช้คำฟุ่มเฟือยหรือให้ข้อมูลเพิ่มเติม  \n",
    "  คำถาม: ______ สถานที่ทำงานเกี่ยวข้องกับการเสริมสร้างศักยภาพให้พนักงาน ตัวอย่างเช่น 'job enrichment'  \n",
    "  ตัวเลือกคำตอบ: A: Re-invigorating, B: Re-flourishing, C: Revitalizing, D: Rehumanizing\"\n",
    "\n",
    "  2. `prediction`:  \n",
    "  - These questions require interpretation of data, forecasting, or estimating outcomes based on patterns.  \n",
    "  - Often found in financial, statistical, or analytical contexts.\n",
    "\n",
    "  Example:  \n",
    "  \"วิเคราะห์ข้อมูลและทวีตเพื่อสรุปว่าราคาปิดของ $gs จะปรับตัวขึ้นหรือลงในวันที่ 2017-12-20 โปรดยืนยันว่าขึ้นหรือลง  \n",
    "  บริบท: วันที่, เปิด, สูง, ต่ำ, ปิด, ปิดปรับ, เพิ่ม 5%, ...  \n",
    "  2017-12-19, 2.0, 2.1, -0.1, -1.4, -1.4, ...\"\n",
    "\n",
    "  ---\n",
    "\n",
    "  **Your task:**  \n",
    "  Classify the following query as either `multiple` or `prediction`.  \n",
    "  **Only return one of the following two words (in lowercase) without explanation**:  \n",
    "  - `multiple`  \n",
    "  - `prediction`\n",
    "\n",
    "  Query:  \n",
    "  \\\"\\\"\\\"{query}\\\"\\\"\\\"\n",
    "  Assistance :\n",
    "  \"\"\"\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"KBTG-Labs/THaLLE-0.1-7B-fa\",\n",
    "    messages=[{\"role\": \"user\", \"content\": f\"{query}\"}]\n",
    ")\n",
    "  return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96c91995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=\"http://0.0.0.0:3000/v1\", api_key=\"focus-deploy\")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"KBTG-Labs/THaLLE-0.1-7B-fa\",\n",
    "    messages=[{\"role\": \"user\", \"content\": f\"Hello\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d88d7707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C: Revitalizing'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"\"\"ตอบคำถามด้วยตัวเลือกที่เหมาะสม A, B, C และ D โปรดตอบด้วยคำตอบที่ถูกต้อง A, B, C หรือ D เท่านั้น อย่าใช้คำฟุ่มเฟือยหรือให้ข้อมูลเพิ่มเติม\n",
    "\n",
    "คำถาม: ______ สถานที่ทำงานเกี่ยวข้องกับการเสริมสร้างศักยภาพให้พนักงาน ตัวอย่างเช่น 'job enrichment' ที่พนักงานได้รับขอบเขตที่ใหญ่ขึ้นในการตัดสินใจว่าจะจัดระเบียบงานของตนอย่างไร หรือ 'job enlargement' ที่พนักงานได้รับมอบหมายงานที่หลากหลายมากขึ้น\n",
    "\n",
    "ตัวเลือกคำตอบ: A: Re-invigorating, B: Re-flourishing, C: Revitalizing, D: Rehumanizing\n",
    "\n",
    "คำตอบ:\"\"\"\n",
    "classify(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
